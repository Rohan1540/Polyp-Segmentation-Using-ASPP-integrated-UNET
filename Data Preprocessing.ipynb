{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a153c515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout,Conv2D, Activation, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, UpSampling2D, concatenate, Conv2DTranspose, Flatten, Concatenate, Reshape,AveragePooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from metrics import dice_loss, dice_coef\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.utils import CustomObjectScope\n",
    "from sklearn.metrics import f1_score, jaccard_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "org_dataset = '/content/drive/My Drive/CVC-ColonDB/CVC-ColonDB'\n",
    "org_images = '/content/drive/My Drive/CVC-ColonDB/CVC-ColonDB/images/'\n",
    "org_masks = '/content/drive/My Drive/CVC-ColonDB/CVC-ColonDB/masks/'\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data(path, split=0.1):\n",
    "    images = sorted(glob(os.path.join(path, \"images/*\")))\n",
    "    masks = sorted(glob(os.path.join(path, \"masks/*\")))\n",
    "\n",
    "    total_size = len(images)\n",
    "    valid_size = int(split * total_size)\n",
    "    test_size = int(split * total_size)\n",
    "\n",
    "    train_x, valid_x = train_test_split(images, test_size=valid_size, random_state=42)\n",
    "    train_y, valid_y = train_test_split(masks, test_size=valid_size, random_state=42)\n",
    "\n",
    "    train_x, test_x = train_test_split(train_x, test_size=test_size, random_state=42)\n",
    "    train_y, test_y = train_test_split(train_y, test_size=test_size, random_state=42)\n",
    "\n",
    "    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n",
    "\n",
    "def read_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_image(image, channels=3)\n",
    "    image = tf.image.resize(image, (256, 256))\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image\n",
    "\n",
    "def read_mask(path):\n",
    "    mask = tf.io.read_file(path)\n",
    "    mask = tf.image.decode_image(mask, channels=1)\n",
    "    mask = tf.image.resize(mask, (256, 256))\n",
    "    mask = tf.cast(mask, tf.float32) / 255.0\n",
    "    return mask\n",
    "\n",
    "def tf_parse(x, y):\n",
    "    def _parse(x, y):\n",
    "        x = read_image(x)\n",
    "        y = read_mask(y)\n",
    "        return x, y\n",
    "\n",
    "    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])\n",
    "    x.set_shape([256, 256, 3])\n",
    "    y.set_shape([256, 256, 1])\n",
    "    return x, y\n",
    "\n",
    "def tf_dataset(x, y, batch=8):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    dataset = dataset.map(tf_parse)\n",
    "    dataset = dataset.batch(batch)\n",
    "    dataset = dataset.repeat()\n",
    "    return dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
